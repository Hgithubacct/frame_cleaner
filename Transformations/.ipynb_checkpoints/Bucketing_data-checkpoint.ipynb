{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure can accesss bucket values and whether it is bottom or top inclusive. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "dummy_data = pd.read_csv('/Users/henry/Desktop/dummdata - Sheet1.csv')\n",
    "\n",
    "\n",
    "\n",
    "#Class for bucketing Data\n",
    "#Class for outlier detection/replcaement or removal\n",
    "#Class for one hot encoding\n",
    "#Class for scaling numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even distinact between min and max of each bucket. \n",
    "class Bucketing:\n",
    "    \n",
    "    def __init__(self, raw_data):\n",
    "        self.raw_data = raw_data\n",
    "        if isinstance(raw_data, pd.DataFrame):\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Must pass in a dataframe')\n",
    "    def even_compartments(self, columns=[], Number_of_buckets = 10, bucket_array =[], replace = False, append=True,\n",
    "                 min_bucket_size = None, max_bucket_size = None, bottom_bucket_inclusive =True):\n",
    "        \n",
    "        data = self.raw_data\n",
    "        data_T = even_size_buckets(raw_data = data, columns=columns, Number_of_buckets=Number_of_buckets\n",
    "                                   ,replace=replace,append=append, \n",
    "                                   min_bucket_size=min_bucket_size,max_bucket_size=max_bucket_size,\n",
    "                                   bottom_bucket_inclusive=bottom_bucket_inclusive)\n",
    "        return data_T\n",
    "    \n",
    "    def customized_buckets(self, columns=[], bucket_array=[], replace=False, append=True,bottom_bucket_inclusive=True):\n",
    "        data = self.raw_data\n",
    "        data_T = custom_buckets(raw_data = data, columns=columns, \n",
    "                                     bucket_array=bucket_array, replace=replace, \n",
    "                                     append=append, \n",
    "                                     bottom_bucket_inclusive=bottom_bucket_inclusive)\n",
    "        return data_T\n",
    "    \n",
    "    def distributed_entries(self,columns=[], Number_of_buckets=10, min_bucket_size = None, \n",
    "                                max_bucket_size = None, replace = False, append = True, \n",
    "                                bottom_bucket_inclusive = True, display_entries = True):\n",
    "        data = self.raw_data\n",
    "\n",
    "        data_T = even_entry_buckets(raw_data = data, columns=columns, Number_of_buckets=Number_of_buckets, \n",
    "                                    min_bucket_size=min_bucket_size, max_bucket_size=max_bucket_size, \n",
    "                                    replace=replace, append=append,\n",
    "                          bottom_bucket_inclusive=bottom_bucket_inclusive, display_entries=display_entries)\n",
    "        \n",
    "\n",
    "        return data_T\n",
    "        \n",
    "        \n",
    "    def normalized_bucket_sizes(self, columns=[], Number_of_buckets = 10, min_stdev = -3, max_stdev =3, \n",
    "                                replace=False,append=True,bottom_bucket_inclusive=True):\n",
    "        data = self.raw_data\n",
    "        \n",
    "        data_T = normalized_buckets(data, columns=columns, Number_of_buckets = Number_of_buckets, min_stdev = min_stdev,\n",
    "                           max_stdev =max_stdev, replace=replace,append=append,bottom_bucket_inclusive=bottom_bucket_inclusive)\n",
    "        return data_T\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even bucket sizes:  ['temperature']\n",
      "\n",
      "column:  temperature \n",
      "min: 80  max: 100  bucket size: 2.0\n",
      "80.0\n",
      "custom bucket sizes:  ['temperature']\n",
      "\n",
      "column:  temperature columns: [80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bottom_bucket_inclusive': True,\n",
       " 'temperature': [80.0,\n",
       "  82.0,\n",
       "  84.0,\n",
       "  86.0,\n",
       "  88.0,\n",
       "  90.0,\n",
       "  92.0,\n",
       "  94.0,\n",
       "  96.0,\n",
       "  98.0,\n",
       "  100.0]}"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tests\n",
    "#Even bucket sizes\n",
    "df_T_obj = Bucketing(dummy_data)\n",
    "df_T_obj.even_compartments(columns=['temperature'],Number_of_buckets=10, min_bucket_size=80, max_bucket_size=100)[1]\n",
    "\n",
    "#custom_buckets\n",
    "#df_T_obj.customized_buckets(columns=['temperature', 'windspeed'], bucket_array=[-60,70],bottom_bucket_inclusive=True)[0]\n",
    "#df_T_obj.distributed_entries(columns=['temperature', 'windspeed'], min_bucket_size=10, max_bucket_size=100)[1]\n",
    "\n",
    "#normalized\n",
    "#df_T_obj.normalized_bucket_sizes(columns=['temperature', 'windspeed'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_buckets(raw_data, columns=[], Number_of_buckets = 10, min_stdev = -3, max_stdev =3, \n",
    "                                replace=False,append=True,bottom_bucket_inclusive=True):\n",
    "    run_through = 0\n",
    "    bucket_df = pd.DataFrame()\n",
    "    Number_of_buckets = int(Number_of_buckets)\n",
    "    bucket_sets = {}\n",
    "    bucket_sets['bottom_bucket_inclusive'] = bottom_bucket_inclusive\n",
    "    for column in columns:\n",
    "        data_iter = raw_data[column]\n",
    "        stdev = np.std(data_iter.values)\n",
    "        mean = np.mean(data_iter.values)\n",
    "        stdev_iter = (max_stdev - (min_stdev))/Number_of_buckets\n",
    "        print(stdev_iter)\n",
    "        buckets = []\n",
    "        sdev_iter = min_stdev\n",
    "        for i in range(0,Number_of_buckets):\n",
    "            bucket = mean + sdev_iter*stdev\n",
    "            buckets.append(bucket)\n",
    "            sdev_iter += stdev_iter\n",
    "        bucket_sets[column] = buckets\n",
    "        just_the_data = Bucketing(raw_data=raw_data).customized_buckets(columns = [column], bucket_array=buckets, replace=replace, append=False, bottom_bucket_inclusive=bottom_bucket_inclusive)[0]\n",
    "        if run_through == 0:\n",
    "                bucket_df = just_the_data\n",
    "        else:\n",
    "            bucket_df = bucket_df.join(just_the_data)\n",
    "        run_through +=1\n",
    "        \n",
    "    base_cols = [column for column in raw_data.columns if column not in columns]\n",
    "\n",
    "    if append == True:\n",
    "        base_df = pd.DataFrame(raw_data[base_cols])\n",
    "        bucket_df = base_df.join(bucket_df)\n",
    "\n",
    "    return bucket_df, bucket_sets\n",
    "# normalized_buckets(dummy_data, columns=['temperature', 'windspeed'], Number_of_buckets = 10, min_stdev = -3, max_stdev =3, \n",
    "#                                 replace=True,append=False,bottom_bucket_inclusive=True)[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_entry_buckets(raw_data,columns, Number_of_buckets, min_bucket_size, max_bucket_size, replace, append, bottom_bucket_inclusive,display_entries):\n",
    "        bucket_df = pd.DataFrame()\n",
    "        run_through = 0\n",
    "        Number_of_buckets = int(Number_of_buckets)\n",
    "        bucket_sets = {}\n",
    "        bucket_sets['bottom_bucket_inclusive'] = bottom_bucket_inclusive\n",
    "        if max_bucket_size != None and min_bucket_size != None:\n",
    "            if int(max_bucket_size) < int(max_bucket_size):\n",
    "                raise ValueError('Max Must be greater than Min')\n",
    "        for column in columns:\n",
    "            Num_bucks = Number_of_buckets\n",
    "            Num_bucks -= 1\n",
    "            entries = list(dummy_data[column])\n",
    "            if str(min_bucket_size).isnumeric() ==True:\n",
    "                entries = [number for number in entries if number >= min_bucket_size]\n",
    "                Num_bucks-=1\n",
    "                if len(entries) < Num_bucks:\n",
    "                    raise ValueError('More buckets than entires')\n",
    "            if str(max_bucket_size).isnumeric() == True:\n",
    "                entries = [number for number in entries if number <= max_bucket_size]\n",
    "                Num_bucks -=1\n",
    "                if len(entries) < Num_bucks:\n",
    "                    raise ValueError('More buckets than entires')\n",
    "            \n",
    "            entries.sort()\n",
    "            items_per_bucket = int(len(entries)/Num_bucks)\n",
    "            bucket_iter = 0\n",
    "            buckets = []\n",
    "            for i in range(0, Num_bucks):\n",
    "                bucket_iter+=int(items_per_bucket-1)\n",
    "                bucket = entries[bucket_iter]\n",
    "                buckets.append(bucket)\n",
    "            if str(min_bucket_size).isnumeric() ==True:\n",
    "                buckets.append(min_bucket_size)\n",
    "\n",
    "            if str(max_bucket_size).isnumeric() == True:\n",
    "                buckets.append(max_bucket_size)\n",
    "            buckets = list(set(buckets))\n",
    "            buckets.sort()\n",
    "            bucket_sets[column] = buckets\n",
    "            just_the_data = Bucketing(raw_data=raw_data).customized_buckets(columns = [column], bucket_array=buckets, replace=replace, append=False, bottom_bucket_inclusive=bottom_bucket_inclusive)[0]\n",
    "            if run_through == 0:\n",
    "                bucket_df = just_the_data\n",
    "            else:\n",
    "                bucket_df = bucket_df.join(just_the_data)\n",
    "            run_through +=1\n",
    "        \n",
    "        if display_entries == True:\n",
    "            for column in bucket_df.columns:\n",
    "                print(column, bucket_df[column].sum())\n",
    "\n",
    "        base_cols = [column for column in raw_data.columns if column not in columns]\n",
    "        if append == True:\n",
    "            base_df = raw_data[base_cols]\n",
    "            bucket_df = base_df.join(bucket_df)\n",
    "            \n",
    "        \n",
    "        return bucket_df, bucket_sets\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Buckets\n",
    "def custom_buckets(raw_data, columns,bucket_array, replace, append, bottom_bucket_inclusive):\n",
    "        bucket_array.sort()\n",
    "        bucket_sets = {}\n",
    "        bucket_sets['bottom_bucket_inclusive'] = bottom_bucket_inclusive\n",
    "        try:\n",
    "            columns[0]\n",
    "            bucket_array[0]\n",
    "        except:\n",
    "            raise ValueError('columns must be a list of columns and bucket_array must be an array of bottom bucket sizes')\n",
    "        if replace == True or replace == False:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('replace must be boolean')\n",
    "        if append == True or append == False:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('append must be boolean')\n",
    "        \n",
    "        print('custom bucket sizes: ', columns)\n",
    "        return_frame = pd.DataFrame()\n",
    "        if bottom_bucket_inclusive == True: \n",
    "            for item in columns:\n",
    "                bucket_sets[item] = bucket_array\n",
    "                try: \n",
    "                    bucketed_data = pd.DataFrame(raw_data[item], columns=[item])\n",
    "                except:\n",
    "                    raise ValueError('no such column: ', item)\n",
    "                \n",
    "                try:\n",
    "                   \n",
    "                    print('\\ncolumn: ', item, 'columns:', str(bucket_array))\n",
    "                    test = float(bucketed_data[item].iloc[0])\n",
    "                except:\n",
    "                    raise ValueError('Bucket column ', item, ' must be numeric')\n",
    "                    \n",
    "                for bucket in range(0,len(bucket_array)+1):\n",
    "                    try:\n",
    "                        if bucket != 0 and bucket != (len(bucket_array)):\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item +'_>='+ str(bucket_start)+ '_<' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] < bucket_end and x[item] >= bucket_start else 0,axis=1)\n",
    "                        elif bucket == 0 and bucket != len(bucket_array) + 1:\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item + '_<' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] < bucket_end else 0,axis=1)\n",
    "                        else:\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            new_column = item + '_>=' + str(bucket_start)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] >= bucket_start else 0,axis=1)\n",
    "                    except:\n",
    "                        raise ValueError('Buckets must be an array of bottom bucket values')\n",
    "                return_frame = pd.concat([return_frame, bucketed_data], axis=1)\n",
    "                \n",
    "            if append == True and replace==True:\n",
    "                return_frame = pd.concat([raw_data, return_frame],axis=1)\n",
    "                return_frame = return_frame.drop(columns=columns)\n",
    "                return return_frame, bucket_sets\n",
    "            elif append==True and replace==False:\n",
    "                return_frame = return_frame.drop(columns=columns)\n",
    "                return_frame = pd.concat([raw_data, return_frame],axis=1)\n",
    "                return return_frame, bucket_sets\n",
    "            elif append==False and replace==True:\n",
    "                return_frame = return_frame.drop(columns=columns)\n",
    "                return return_frame, bucket_sets\n",
    "            elif append==False and replace==False:\n",
    "                return return_frame, bucket_sets\n",
    "       \n",
    "        else: \n",
    "\n",
    "            for item in columns:\n",
    "                bucket_sets[item] = bucket_array\n",
    "                try: \n",
    "                    bucketed_data = pd.DataFrame(raw_data[item], columns=[item])\n",
    "                except:\n",
    "                    raise ValueError('no such column: ', item)\n",
    "\n",
    "                try:\n",
    "\n",
    "                    print('\\ncolumn: ', item, 'columns:', str(bucket_array))\n",
    "                    test = float(bucketed_data[item].iloc[0])\n",
    "                except:\n",
    "                    raise ValueError('Bucket column ', item, ' must be numeric')\n",
    "\n",
    "                for bucket in range(0,len(bucket_array)+1):\n",
    "                    try:\n",
    "                        if bucket != 0 and bucket != (len(bucket_array)):\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item +'_>'+ str(bucket_start)+ '_<=' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] <= bucket_end and x[item] > bucket_start else 0,axis=1)\n",
    "                        elif bucket == 0 and bucket != len(bucket_array) + 1:\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item + '_<=' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] <= bucket_end else 0,axis=1)\n",
    "                        else:\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            new_column = item + '_>' + str(bucket_start)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] > bucket_start else 0,axis=1)\n",
    "                    except:\n",
    "                        raise ValueError('Buckets must be an array of bottom bucket values')\n",
    "                return_frame = pd.concat([return_frame, bucketed_data], axis=1)\n",
    "\n",
    "\n",
    "        if append == True and replace==True:\n",
    "            return_frame = pd.concat([raw_data, return_frame],axis=1)\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return return_frame, bucket_sets\n",
    "        elif append==True and replace==False:\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return_frame = pd.concat([raw_data, return_frame],axis=1)\n",
    "            return return_frame, bucket_sets\n",
    "        elif append==False and replace==True:\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return return_frame, bucket_sets\n",
    "        elif append==False and replace==False:\n",
    "            return return_frame, bucket_sets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Gives even bucket sizes\n",
    "def even_size_buckets(raw_data, columns, Number_of_buckets,replace,append, min_bucket_size,max_bucket_size, bottom_bucket_inclusive):\n",
    "    run_through = 0\n",
    "    bucket_sets = {}\n",
    "    bucket_sets['bottom_bucket_inclusive'] = bottom_bucket_inclusive\n",
    "    if columns[0]:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('columns must be a list of columns')\n",
    "    if str(Number_of_buckets).isnumeric():\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Number of buckets must be a number')\n",
    "    if replace == True or replace == False:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('replace must be boolean')\n",
    "    if append == True or append == False:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('append must be boolean')\n",
    "    \n",
    "    print('even bucket sizes: ', columns)\n",
    "    return_frame = pd.DataFrame()\n",
    "\n",
    "    for item in columns:\n",
    "        try: \n",
    "            bucketed_data = pd.DataFrame(raw_data[item], columns=[item])\n",
    "            data = bucketed_data.values\n",
    "        except:\n",
    "            raise ValueError('no such column: ', item)\n",
    "        if str(min_bucket_size).isnumeric():\n",
    "            minimum = min_bucket_size\n",
    "        else:\n",
    "            minimum = min(data)\n",
    "        if str(max_bucket_size).isnumeric():\n",
    "            maximum = max_bucket_size\n",
    "        else:\n",
    "            maximum = max(data)\n",
    "        try:\n",
    "            bucket_size = (maximum-minimum)/Number_of_buckets\n",
    "            print('\\ncolumn: ', item, '\\nmin:', str(minimum), ' max:', str(maximum), ' bucket size:', str(bucket_size))\n",
    "        except:\n",
    "            raise ValueError('Bucket column ', item, ' must be numeric')\n",
    "\n",
    "        bucket_start = float(minimum)\n",
    "\n",
    "        buckets = []\n",
    "        bucket_i = bucket_start\n",
    "        print(bucket_i)\n",
    "        buckets.append(bucket_i)\n",
    "        for bucket in range(0, int(Number_of_buckets)):\n",
    "\n",
    "            bucket_i += bucket_size\n",
    "            bucket_i = float(bucket_i)\n",
    "            buckets.append(bucket_i)\n",
    "        bucket_sets[item] = buckets\n",
    "        just_the_data = Bucketing(raw_data=raw_data).customized_buckets(columns = [item], bucket_array=buckets, replace=replace, append=False, bottom_bucket_inclusive=bottom_bucket_inclusive)[0]\n",
    "        if run_through == 0:\n",
    "            bucket_df = just_the_data\n",
    "        else:\n",
    "            bucket_df = bucket_df.join(just_the_data)\n",
    "        run_through +=1\n",
    "        \n",
    "\n",
    "    base_cols = [column for column in raw_data.columns if column not in columns]\n",
    "    if append == True:\n",
    "        base_df = raw_data[base_cols]\n",
    "        bucket_df = base_df.join(bucket_df)\n",
    "    return bucket_df, bucket_sets\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
