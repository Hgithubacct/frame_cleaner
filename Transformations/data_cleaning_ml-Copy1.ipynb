{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "dummy_data = pd.read_csv('/Users/henry/Desktop/dummdata - Sheet1.csv')\n",
    "\n",
    "#Buckets + outlier detection and remove/replacement\n",
    "\n",
    "#Class for bucketing Data\n",
    "#Class for outlier detection/replcaement or removal\n",
    "#Class for one hot encoding\n",
    "#Class for scaling numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#either min or max bucket has to be inclusive add option. \n",
    "class Even_Bucketing_Sizes:\n",
    "    \n",
    "    def __init__(self, raw_data):\n",
    "        self.raw_data = raw_data\n",
    "        if isinstance(raw_data, pd.DataFrame):\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Must pass in a dataframe')\n",
    "    \n",
    "   \n",
    "    def bucketing(self, bucket_type='even_compartments', columns=[], Number_of_buckets = 10, bucket_array =[], replace = False, append=True,\n",
    "                 min_bucket_size = None, max_bucket_size = None, bottom_bucket_inclusive =True):\n",
    "        if bucket_type == 'even_entries':\n",
    "            self.even_entry_buckets(columns, Number_of_buckets)\n",
    "        elif bucket_type == 'even_bucket_sizes':\n",
    "            data_T = self.even_size_buckets(columns, Number_of_buckets,replace,append, min_bucket_size,max_bucket_size, bottom_bucket_inclusive)\n",
    "            return data_T\n",
    "        elif bucket_type == 'custom':\n",
    "            data_T = self.custom_buckets(columns, bucket_array, replace, append, bottom_bucket_inclusive)\n",
    "            return data_T\n",
    "        elif bucket_type == 'rate_of_change':\n",
    "            self.minmax_bs()\n",
    "        else:\n",
    "            raise ValueError('invalid bucket type options are: custom, even_entries, even_bucket_sizes and min_max_bs')\n",
    "            \n",
    "    #Gives buckets with an around an even number of entries per bucket with given number of buckets.\n",
    "    def even_entry_buckets(self,columns = []):\n",
    "        print('even_entries_per_bucket_buckets')\n",
    "        \n",
    "    #Gives even bucket sizes\n",
    "    def even_size_buckets(self,columns, Number_of_buckets,replace,append, min_bucket_size,max_bucket_size, bottom_bucket_inclusive):\n",
    "        if columns[0]:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('columns must be a list of columns')\n",
    "        if str(Number_of_buckets).isnumeric():\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Number of buckets must be a number')\n",
    "        if replace == True or replace == False:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('replace must be boolean')\n",
    "        if append == True or append == False:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('append must be boolean')\n",
    "        \n",
    "        print('even bucket sizes: ', columns)\n",
    "        return_frame = pd.DataFrame()\n",
    "        if bottom_bucket_inclusive == True: \n",
    "            for item in columns:\n",
    "                try: \n",
    "                    bucketed_data = pd.DataFrame(self.raw_data[item], columns=[item])\n",
    "                except:\n",
    "                    raise ValueError('no such column: ', item)\n",
    "                if str(min_bucket_size).isnumeric():\n",
    "                    minimum = min_bucket_size\n",
    "                else:\n",
    "                    minimum = min(data)\n",
    "                if str(max_bucket_size).isnumeric():\n",
    "                    maximum = max_bucket_size\n",
    "                else:\n",
    "                    maximum = max(data)\n",
    "                try:\n",
    "                    bucket_size = (maximum-minimum)/Number_of_buckets\n",
    "                    print('\\ncolumn: ', item, '\\nmin:', str(minimum), ' max:', str(maximum), ' bucket size:', str(bucket_size))\n",
    "                except:\n",
    "                    raise ValueError('Bucket column ', item, ' must be numeric')\n",
    "\n",
    "                bucket_start = minimum\n",
    "                \n",
    "\n",
    "                for bucket in range(0, int(Number_of_buckets)):\n",
    "                    bucket_end = bucket_start + bucket_size\n",
    "                    if bucket == 0:\n",
    "                        less_than_min_column_name = str(item) + '_<_' + str(minimum)\n",
    "                        bucketed_data[less_than_min_column_name] = bucketed_data.apply(lambda x: 1 if x[item] < minimum else 0,axis=1)\n",
    "\n",
    "\n",
    "                    column_name = str(item)+ '_>=_' + str(bucket_start) + '_<' + str(bucket_end) \n",
    "                    bucketed_data[column_name] = bucketed_data.apply(lambda x: 1 if x[item]>= bucket_start and x[item] < bucket_end else 0,axis=1)\n",
    "                    if bucket == int(Number_of_buckets) -1:\n",
    "                        more_than_max_column_name = str(item) + '_>=_' + str(maximum)\n",
    "                        bucketed_data[more_than_max_column_name] = bucketed_data.apply(lambda x: 1 if x[item]>= maximum else 0,axis=1)\n",
    "\n",
    "                    bucket_start +=bucket_size\n",
    "                return_frame = pd.concat([return_frame, bucketed_data], axis=1)\n",
    "        else:\n",
    "            for item in columns:\n",
    "                try: \n",
    "                    bucketed_data = pd.DataFrame(self.raw_data[item], columns=[item])\n",
    "                except:\n",
    "                    raise ValueError('no such column: ', item)\n",
    "                if str(min_bucket_size).isnumeric():\n",
    "                    minimum = min_bucket_size\n",
    "                else:\n",
    "                    minimum = min(data)\n",
    "                if str(max_bucket_size).isnumeric():\n",
    "                    maximum = max_bucket_size\n",
    "                else:\n",
    "                    maximum = max(data)\n",
    "                try:\n",
    "                    bucket_size = (maximum-minimum)/Number_of_buckets\n",
    "                    print('\\ncolumn: ', item, '\\nmin:', str(minimum), ' max:', str(maximum), ' bucket size:', str(bucket_size))\n",
    "                except:\n",
    "                    raise ValueError('Bucket column ', item, ' must be numeric')\n",
    "\n",
    "                bucket_start = minimum\n",
    "                \n",
    "                for bucket in range(0, int(Number_of_buckets)):\n",
    "                    bucket_end = bucket_start + bucket_size\n",
    "                    if bucket == 0:\n",
    "                        less_than_min_column_name = str(item) + '_<=_' + str(minimum)\n",
    "                        bucketed_data[less_than_min_column_name] = bucketed_data.apply(lambda x: 1 if x[item] <= minimum else 0,axis=1)\n",
    "\n",
    "\n",
    "                    column_name = str(item)+ '_>_' + str(bucket_start) + '_<=' + str(bucket_end) \n",
    "                    bucketed_data[column_name] = bucketed_data.apply(lambda x: 1 if x[item] > bucket_start and x[item] <= bucket_end else 0,axis=1)\n",
    "                    if bucket == int(Number_of_buckets) -1:\n",
    "                        more_than_max_column_name = str(item) + '_>_' + str(maximum)\n",
    "                        bucketed_data[more_than_max_column_name] = bucketed_data.apply(lambda x: 1 if x[item]> maximum else 0,axis=1)\n",
    "\n",
    "                    bucket_start +=bucket_size\n",
    "                return_frame = pd.concat([return_frame, bucketed_data], axis=1)\n",
    "                \n",
    "                \n",
    "        if append == True and replace==True:\n",
    "            return_frame = pd.concat([self.raw_data, return_frame],axis=1)\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return return_frame\n",
    "        elif append==True and replace==False:\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return_frame = pd.concat([self.raw_data, return_frame],axis=1)\n",
    "            return return_frame\n",
    "        elif append==False and replace==True:\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return return_frame\n",
    "        elif append==False and replace==False:\n",
    "            return return_frame\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def custom_buckets(self, columns,bucket_array, replace, append, bottom_bucket_inclusive):\n",
    "        bucket_array.sort()\n",
    "        try:\n",
    "            columns[0]\n",
    "            bucket_array[0]\n",
    "        except:\n",
    "            raise ValueError('columns must be a list of columns and bucket_array must be an array of bottom bucket sizes')\n",
    "        if replace == True or replace == False:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('replace must be boolean')\n",
    "        if append == True or append == False:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('append must be boolean')\n",
    "        \n",
    "        print('custom bucket sizes: ', columns)\n",
    "        return_frame = pd.DataFrame()\n",
    "        if bottom_bucket_inclusive == True: \n",
    "            for item in columns:\n",
    "                try: \n",
    "                    bucketed_data = pd.DataFrame(self.raw_data[item], columns=[item])\n",
    "                except:\n",
    "                    raise ValueError('no such column: ', item)\n",
    "                \n",
    "                try:\n",
    "                   \n",
    "                    print('\\ncolumn: ', item, 'columns:', str(bucket_array))\n",
    "                    test = float(bucketed_data[item].iloc[0])\n",
    "                except:\n",
    "                    raise ValueError('Bucket column ', item, ' must be numeric')\n",
    "                    \n",
    "                for bucket in range(0,len(bucket_array)+1):\n",
    "                    try:\n",
    "                        if bucket != 0 and bucket != (len(bucket_array)):\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item +'_>='+ str(bucket_start)+ '_<' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] < bucket_end and x[item] >= bucket_start else 0,axis=1)\n",
    "                        elif bucket == 0 and bucket != len(bucket_array) + 1:\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item + '_<' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] < bucket_end else 0,axis=1)\n",
    "                        else:\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            new_column = item + '_>=' + str(bucket_start)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] >= bucket_start else 0,axis=1)\n",
    "                    except:\n",
    "                        raise ValueError('Buckets must be an array of bottom bucket values')\n",
    "                return_frame = pd.concat([return_frame, bucketed_data], axis=1)\n",
    "                \n",
    "                \n",
    "            if append == True and replace==True:\n",
    "                return_frame = pd.concat([self.raw_data, return_frame],axis=1)\n",
    "                return_frame = return_frame.drop(columns=columns)\n",
    "                return return_frame\n",
    "            elif append==True and replace==False:\n",
    "                return_frame = return_frame.drop(columns=columns)\n",
    "                return_frame = pd.concat([self.raw_data, return_frame],axis=1)\n",
    "                return return_frame\n",
    "            elif append==False and replace==True:\n",
    "                return_frame = return_frame.drop(columns=columns)\n",
    "                return return_frame\n",
    "            elif append==False and replace==False:\n",
    "                return return_frame\n",
    "       \n",
    "        else: \n",
    "\n",
    "            for item in columns:\n",
    "                try: \n",
    "                    bucketed_data = pd.DataFrame(self.raw_data[item], columns=[item])\n",
    "                except:\n",
    "                    raise ValueError('no such column: ', item)\n",
    "\n",
    "                try:\n",
    "\n",
    "                    print('\\ncolumn: ', item, 'columns:', str(bucket_array))\n",
    "                    test = float(bucketed_data[item].iloc[0])\n",
    "                except:\n",
    "                    raise ValueError('Bucket column ', item, ' must be numeric')\n",
    "\n",
    "                for bucket in range(0,len(bucket_array)+1):\n",
    "                    try:\n",
    "                        if bucket != 0 and bucket != (len(bucket_array)):\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item +'_>'+ str(bucket_start)+ '_<=' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] <= bucket_end and x[item] > bucket_start else 0,axis=1)\n",
    "                        elif bucket == 0 and bucket != len(bucket_array) + 1:\n",
    "                            bucket_end = bucket_array[bucket]\n",
    "                            new_column = item + '_<=' + str(bucket_end)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] <= bucket_end else 0,axis=1)\n",
    "                        else:\n",
    "                            bucket_start = bucket_array[bucket-1]\n",
    "                            new_column = item + '_>' + str(bucket_start)\n",
    "                            bucketed_data[new_column] = bucketed_data.apply(lambda x: 1 if x[item] > bucket_start else 0,axis=1)\n",
    "                    except:\n",
    "                        raise ValueError('Buckets must be an array of bottom bucket values')\n",
    "                return_frame = pd.concat([return_frame, bucketed_data], axis=1)\n",
    "\n",
    "\n",
    "        if append == True and replace==True:\n",
    "            return_frame = pd.concat([self.raw_data, return_frame],axis=1)\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return return_frame\n",
    "        elif append==True and replace==False:\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return_frame = pd.concat([self.raw_data, return_frame],axis=1)\n",
    "            return return_frame\n",
    "        elif append==False and replace==True:\n",
    "            return_frame = return_frame.drop(columns=columns)\n",
    "            return return_frame\n",
    "        elif append==False and replace==False:\n",
    "            return return_frame\n",
    "\n",
    "\n",
    "                    \n",
    "       \n",
    "                \n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom bucket sizes:  ['temperature']\n",
      "\n",
      "column:  temperature columns: [10, 19, 31, 41, 51, 61, 71, 79, 90, 99]\n",
      "custom bucket sizes:  ['windspeed']\n",
      "\n",
      "column:  windspeed columns: [13, 16, 19, 22, 25, 28, 31, 34, 37, 40]\n",
      "temperature_<=10 50\n",
      "temperature_>10_<=19 54\n",
      "temperature_>19_<=31 51\n",
      "temperature_>31_<=41 43\n",
      "temperature_>41_<=51 52\n",
      "temperature_>51_<=61 46\n",
      "temperature_>61_<=71 50\n",
      "temperature_>71_<=79 48\n",
      "temperature_>79_<=90 53\n",
      "temperature_>90_<=99 45\n",
      "temperature_>99 7\n",
      "windspeed_<=13 63\n",
      "windspeed_>13_<=16 39\n",
      "windspeed_>16_<=19 50\n",
      "windspeed_>19_<=22 61\n",
      "windspeed_>22_<=25 42\n",
      "windspeed_>25_<=28 40\n",
      "windspeed_>28_<=31 49\n",
      "windspeed_>31_<=34 55\n",
      "windspeed_>34_<=37 43\n",
      "windspeed_>37_<=40 57\n",
      "windspeed_>40 0\n"
     ]
    }
   ],
   "source": [
    "#Min and Max will be even entries between those values will get as close as possible to even entries\n",
    "#How to do when two bucket bottoms are the same and how to deal with first and last buckets. \n",
    "\n",
    "#Need to return alot of the stuff such as buckets for this one to the user so can use in scoring. \n",
    "def even_entry_buckets(data,columns, Number_of_buckets, replace, append, bottom_bucket_inclusive):\n",
    "        bucket_df = pd.DataFrame()\n",
    "        run_through = 0\n",
    "        for column in columns:\n",
    "            entries = list(dummy_data[column])\n",
    "            entries.sort()\n",
    "            items_per_bucket = len(entries)/Number_of_buckets\n",
    "            bucket_iter = 0 \n",
    "            buckets = []\n",
    "            for i in range(0, Number_of_buckets):\n",
    "                bucket_iter+=int(items_per_bucket)\n",
    "                bucket = entries[bucket_iter]\n",
    "                buckets.append(bucket)\n",
    "                \n",
    "        \n",
    "            \n",
    "            just_the_data = Bucketing_Data(raw_data=data).bucketing(bucket_type='custom', columns = [column], bucket_array=buckets, replace=True, append=False, bottom_bucket_inclusive=bottom_bucket_inclusive)\n",
    "            if run_through == 0:\n",
    "                bucket_df = just_the_data\n",
    "            else:\n",
    "                bucket_df = bucket_df.join(just_the_data)\n",
    "            run_through +=1\n",
    "        return bucket_df\n",
    "\n",
    "data = even_entry_buckets(data = dummy_data, columns=['temperature', 'windspeed'], Number_of_buckets=10, replace=True, append=True, bottom_bucket_inclusive=False)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "for column in data.columns:\n",
    "    print(column, data[column].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Even bucket sizes. \n",
    "# my_data = Bucketing_Data(raw_data=dummy_data).bucketing(bucket_type='even_bucket_sizes', columns=['temperature'],Number_of_buckets=5, replace=False,append=True, min_bucket_size=30, max_bucket_size=70, bottom_bucket_inclusive=False)\n",
    "# my_data.head(50)\n",
    "\n",
    "#Custom Buckets\n",
    "#object_ = Bucketing_Data(raw_data=dummy_data)\n",
    "# test = object_.bucketing(bucket_type='custom', columns=['temperature', 'windspeed'], \n",
    "#                   bucket_array=[10,20,40,30,70.5,100,110],replace=False, append=False, bottom_bucket_inclusive=False)\n",
    "                 \n",
    "\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
